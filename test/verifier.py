import psycopg2
import torch
import numpy as np
import pandas as pd
import os
import joblib
import re
from underthesea import sent_tokenize
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from sentence_transformers import SentenceTransformer, CrossEncoder
from dotenv import load_dotenv

load_dotenv()

DB_CONFIG = {
    "dbname": os.getenv("POSTGRES_DB", "vnexpress_scraper"),
    "user": os.getenv("POSTGRES_USER", "admin"),
    "password": os.getenv("POSTGRES_PASSWORD", "admin"),
    "host": os.getenv("DB_HOST", "localhost"),
    "port": os.getenv("DB_PORT", "5432")
}

class AdvancedFactChecker:
    def __init__(self):
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        print(f"üöÄ KH·ªûI ƒê·ªòNG H·ªÜ TH·ªêNG TR√äN {self.device.upper()}...")

        # 1. LOAD CLAIM DETECTOR (PhoBERT)
        print("   ‚îú‚îÄ [1/4] Loading Claim Detector...")
        claim_path = "./claim_detector_model"
        if os.path.exists(claim_path):
            self.claim_tokenizer = AutoTokenizer.from_pretrained(claim_path)
            self.claim_model = AutoModelForSequenceClassification.from_pretrained(claim_path).to(self.device)
        else:
            print("   ‚ö†Ô∏è Kh√¥ng th·∫•y Claim Model, s·∫Ω d√πng lu·∫≠t Heuristic.")
            self.claim_model = None

        # 2. LOAD RETRIEVER (Bi-Encoder)
        print("   ‚îú‚îÄ [2/4] Loading Retriever...")
        self.retriever = SentenceTransformer('bkai-foundation-models/vietnamese-bi-encoder', device=self.device)

        # 3. LOAD VERIFIER (Cross-Encoder Fine-tuned)
        print("   ‚îú‚îÄ [3/4] Loading NLI Verifier...")
        possible_paths = ["model/my_model_v2/final_model_saved", "my_model_v2/final_model_saved", "my_model"]
        nli_path = next((p for p in possible_paths if os.path.exists(p)), None)
        
        if nli_path:
            print(f"      -> D√πng model: {nli_path}")
            self.verifier = CrossEncoder(nli_path, device=self.device, model_kwargs={"ignore_mismatched_sizes": True})
        else:
            print("      ‚ö†Ô∏è D√πng model g·ªëc (k√©m ch√≠nh x√°c h∆°n).")
            self.verifier = CrossEncoder("cross-encoder/nli-distilroberta-base", num_labels=1, device=self.device)

        # 4. LOAD FINAL CLASSIFIER (XGBoost/Sklearn)
        print("   ‚îú‚îÄ [4/4] Loading Final Classifier...")
        clf_path = 'final_classifier.pkl'
        self.final_clf = joblib.load(clf_path) if os.path.exists(clf_path) else None
            
        print("‚úÖ H·ªÜ TH·ªêNG S·∫¥N S√ÄNG!\n")

    def super_logic_check(self, claim, evidence):
        """
        B·ªô l·ªçc Logic C·ª©ng (Hard Rules) - Phi√™n b·∫£n Fix l·ªói 90.0 vs 9.0
        Th·ª© t·ª± ∆∞u ti√™n: S·ªê LI·ªÜU > NG√ÄY TH√ÅNG > TEXT OVERLAP
        """
        c_lower = claim.lower().strip()
        e_lower = evidence.lower().strip()
        
        # --- 1. LOGIC S·ªê LI·ªÜU (NUMBER CHECK) - QUAN TR·ªåNG NH·∫§T ---
        # Regex b·∫Øt s·ªë th·ª±c (9.0, 90.0, 1,500) v√† s·ªë nguy√™n
        # Pattern: S·ªë + (d·∫•u ch·∫•m/ph·∫©y + s·ªë) tu·ª≥ ch·ªçn
        num_pattern = r'\d+(?:[.,]\d+)?'
        
        c_nums = re.findall(num_pattern, c_lower)
        e_nums = re.findall(num_pattern, e_lower)
        
        # H√†m chu·∫©n h√≥a s·ªë (9,0 -> 9.0)
        def parse_num(s):
            try: return float(s.replace(',', '.'))
            except: return None

        # Danh s√°ch s·ªë trong Evidence (ƒë·ªïi sang float ƒë·ªÉ so s√°nh gi√° tr·ªã)
        e_vals = [parse_num(x) for x in e_nums if parse_num(x) is not None]
        
        missing_nums = []
        for c_str in c_nums:
            c_val = parse_num(c_str)
            if c_val is None: continue
            
            # B·ªè qua c√°c s·ªë ng√†y th√°ng (ƒë·ªÉ logic ng√†y th√°ng x·ª≠ l√Ω sau)
            # VD: tr√°nh b·∫Øt l·ªói s·ªë 4 trong "ng√†y 4/1" n·∫øu logic ng√†y th√°ng l√†m t·ªët
            # Nh∆∞ng ·ªü ƒë√¢y ta c·ª© check ch·∫∑t.
            
            # Logic: S·ªë trong Claim ph·∫£i T·ªíN T·∫†I trong Evidence (sai s·ªë c·ª±c nh·ªè)
            found = False
            for e_val in e_vals:
                if abs(c_val - e_val) < 0.001: # Ch·∫•p nh·∫≠n sai s·ªë float
                    found = True
                    break
            
            if not found:
                missing_nums.append(c_str)
        
        if missing_nums:
            # N·∫øu sai s·ªë -> REFUTED ngay l·∫≠p t·ª©c
            return "REFUTED", f"Sai s·ªë li·ªáu: Claim c√≥ {missing_nums} nh∆∞ng Evidence kh√¥ng c√≥ (t√¨m th·∫•y {e_nums})."

        # --- 2. LOGIC NG√ÄY TH√ÅNG (DATE CHECK) ---
        month_match = re.search(r'th√°ng (\d{1,2})', c_lower)
        if month_match:
            m_claim = int(month_match.group(1))
            patterns = [
                f"th√°ng {m_claim}", f"th√°ng {m_claim:02d}",
                f"/{m_claim}/", f"/{m_claim:02d}/",
                f"-{m_claim}-", f"-{m_claim:02d}-",
                f"/{m_claim} ", f"/{m_claim:02d} ",
                f"/{m_claim}.", f"/{m_claim:02d}.",
                f"/{m_claim}", f"/{m_claim:02d}"
            ]
            has_month = any(p in e_lower for p in patterns)
            if not has_month:
                regex_date = fr"[\/\-]0?{m_claim}[\/\-]"
                if not re.search(regex_date, e_lower):
                    return "REFUTED", f"Sai th√°ng: Claim th√°ng {m_claim} nh∆∞ng Evidence kh√¥ng c√≥."

        # --- 3. LOGIC TR√ôNG KH·ªöP VƒÇN B·∫¢N (TEXT OVERLAP) ---
        # Ch·ªâ ch·∫°y khi S·ªë li·ªáu v√† Ng√†y th√°ng ƒë√£ OK
        c_clean = c_lower.replace('\n', ' ')
        e_clean = e_lower.replace('\n', ' ')
        
        if e_clean in c_clean or c_clean in e_clean:
            return "SUPPORTED", 1.0

        c_tokens = set(c_clean.split())
        e_tokens = set(e_clean.split())
        if not c_tokens or not e_tokens: return "PASS", "No tokens"

        overlap_ratio = len(c_tokens.intersection(e_tokens)) / min(len(c_tokens), len(e_tokens))
        
        if overlap_ratio > 0.85:
             return "SUPPORTED", 0.95

        return "PASS", "Logic OK"

    def extract_claims(self, text):
        sentences = sent_tokenize(text)
        if not sentences: return []
        
        candidates = [s for s in sentences if len(s.split()) > 5]
        final_claims = []
        
        if self.claim_model:
            inputs = self.claim_tokenizer(candidates, padding=True, truncation=True, max_length=128, return_tensors="pt").to(self.device)
            with torch.no_grad():
                outputs = self.claim_model(**inputs)
                scores = torch.nn.functional.softmax(outputs.logits, dim=1)[:, 1].cpu().numpy()
            
            for i, sent in enumerate(candidates):
                has_digit = bool(re.search(r'\d+', sent))
                # L·∫•y n·∫øu AI t·ª± tin ho·∫∑c c√≥ s·ªë li·ªáu (tr√°nh b·ªè s√≥t ng√†y th√°ng)
                if scores[i] > 0.4 or has_digit: 
                    final_claims.append(sent)
        else:
            final_claims = [s for s in candidates if any(c.isdigit() for c in s)]
            
        return final_claims

    def verify(self, article_text):
        print("="*60)
        print("üìù B·∫ÆT ƒê·∫¶U KI·ªÇM TRA B√ÄI VI·∫æT...")
        claims = self.extract_claims(article_text)
        print(f"üîç T√¨m th·∫•y {len(claims)} c√¢u c·∫ßn ki·ªÉm ch·ª©ng (Claims).")
        
        if not claims: 
            return {"status": "NEUTRAL", "explanation": "Kh√¥ng t√¨m th·∫•y th√¥ng tin ƒë·ªãnh l∆∞·ª£ng ƒë·ªÉ ki·ªÉm ch·ª©ng.", "details": []}

        # --- GIAI ƒêO·∫†N 1: RETRIEVAL (T√åM KI·∫æM) ---
        print("üì° ƒêang truy xu·∫•t b·∫±ng ch·ª©ng t·ª´ Kho tri th·ª©c...")
        claim_vectors = self.retriever.encode(claims)
        conn = psycopg2.connect(**DB_CONFIG)
        cur = conn.cursor()
        
        verified_details = []
        
        for i, claim in enumerate(claims):
            # T√¨m top 5 c√¢u g·∫ßn nh·∫•t
            cur.execute("""
                SELECT content, (embedding <=> %s::vector) as distance
                FROM sentence_store
                ORDER BY distance ASC
                LIMIT 5; 
            """, (claim_vectors[i].tolist(),))
            results = cur.fetchall()
            
            # Ng∆∞·ª°ng 0.6 ƒë·ªÉ b·∫Øt Paraphrase
            valid_evidence = [r for r in results if r[1] < 0.60]
            
            if not valid_evidence:
                verified_details.append({"claim": claim, "status": "NEI", "score": 0.5, "evidence": "Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu ƒë·ªëi chi·∫øu."})
                continue
            
            # L·∫•y c√¢u b·∫±ng ch·ª©ng t·ªët nh·∫•t (Distance nh·ªè nh·∫•t)
            best_evid_text = valid_evidence[0][0]
            best_dist = valid_evidence[0][1]
            
            # --- GIAI ƒêO·∫†N 2: VERIFICATION (LOGIC + AI) ---
            
            # A. Ki·ªÉm tra Logic C·ª©ng
            # H√†m logic b√¢y gi·ªù tr·∫£ v·ªÅ (Status, Message/Score)
            logic_result = self.super_logic_check(claim, best_evid_text)
            logic_status, logic_info = self.super_logic_check(claim, best_evid_text)
            
            if logic_status == "REFUTED":
                status = "REFUTED"
                final_score = 0.0  # ƒêi·ªÉm 0 tr√≤n trƒ©nh
                print(f"   üõë LOGIC CATCH: {logic_info}")
            
            elif logic_status == "SUPPORTED":
                status = "SUPPORTED"
                final_score = float(logic_info)
            else:
                # Logic PASS -> D√πng AI ch·∫•m
                pairs = [[best_evid_text, claim]]
                nli_score = float(self.verifier.predict(pairs)[0])
                final_score = nli_score
                
                if final_score > 0.65: status = "SUPPORTED"
                elif final_score < 0.35: status = "REFUTED"
                else: status = "NEUTRAL"
                
                # Boost ƒëi·ªÉm n·∫øu Logic PASS v√† NLI > 0.55
                if logic_status == "PASS" and final_score > 0.55:
                    status = "SUPPORTED"
                    final_score = 0.85

            verified_details.append({
                "claim": claim, "status": status, "evidence": best_evid_text, "score": final_score
            })

        cur.close()
        conn.close()

        # --- T·ªîNG H·ª¢P K·∫æT QU·∫¢ ---
        scores = [x['score'] for x in verified_details if x['status'] != 'NEI']
        
        if not scores: 
            final_status = "NEUTRAL"
            confidence = 0.5
            explanation = "Ch∆∞a ƒë·ªß d·ªØ li·ªáu trong kho tri th·ª©c."
        # Quy t·∫Øc: 1 c√¢u sai -> C·∫£ b√†i sai (Tin gi·∫£ th∆∞·ªùng tr·ªôn 9 th·∫≠t 1 gi·∫£)
        elif any(x['status'] == 'REFUTED' for x in verified_details):
            final_status = "FAKE"
            confidence = 1.0 # R·∫•t t·ª± tin l√† Fake
            explanation = "H·ªá th·ªëng ph√°t hi·ªán m√¢u thu·∫´n v·ªÅ s·ªë li·ªáu ho·∫∑c th·ªùi gian v·ªõi d·ªØ li·ªáu g·ªëc."
        elif np.mean(scores) > 0.7:
            final_status = "REAL"
            confidence = np.mean(scores)
            explanation = "N·ªôi dung kh·ªõp v·ªõi d·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c x√°c th·ª±c."
        else:
            final_status = "NEUTRAL"
            confidence = 0.5
            explanation = "Th√¥ng tin ch∆∞a r√µ r√†ng ho·∫∑c g√¢y tranh c√£i."

        print("-" * 60)
        print(f"ü§ñ K·∫æT LU·∫¨N CU·ªêI C√ôNG: {final_status} (ƒê·ªô tin c·∫≠y: {confidence:.2%})")
        print(f"üìù Gi·∫£i th√≠ch: {explanation}")
        print("=" * 60)
        
        return {"status": final_status, "confidence": confidence, "explanation": explanation, "details": verified_details}

if __name__ == "__main__":
    checker = AdvancedFactChecker()
    
    # --- CH·∫†Y TH·ª¨ ---
    print("\n>>> TEST CASE 1: B√°o Gi·∫£ (Nisha Patel - Sai ng√†y th√°ng)")
    fake_news = """
    Fadi b·ªã b·∫Øt v√¨ t·ªôi gi·∫øt v·ª£ v√†o ng√†y 32/2/2007. 
    Ng√†y 56/5/2008, Fadi b·ªã k·∫øt t·ªôi.
    """
    checker.verify(fake_news)

    print("\n>>> TEST CASE 2: B√°o Th·∫≠t (V-League)")
    real_news = "V-League 2024-2025 d·ª± ki·∫øn khai m·∫°c v√†o th√°ng 8."
    checker.verify(real_news)
    
    print("\n>>> TEST CASE 3: B√°o Gi·∫£ (V-League sai th√°ng)")
    fake_vleague = "V-League 2024-2025 d·ª± ki·∫øn khai m·∫°c v√†o th√°ng 12 nƒÉm nay."
    checker.verify(fake_vleague)