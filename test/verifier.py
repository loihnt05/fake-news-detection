import psycopg2
import torch
import numpy as np
from sentence_transformers import SentenceTransformer, CrossEncoder
from underthesea import sent_tokenize
import os
from dotenv import load_dotenv

load_dotenv()

# C·∫•u h√¨nh DB
DB_CONFIG = {
    "dbname": os.getenv("POSTGRES_DB", "vnexpress_scraper"),
    "user": os.getenv("POSTGRES_USER", "admin"),
    "password": os.getenv("POSTGRES_PASSWORD", "admin"),
    "host": os.getenv("DB_HOST", "localhost"),
    "port": os.getenv("DB_PORT", "5432")
}

class FactCheckerPipeline:
    def __init__(self):
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        print(f"üöÄ Initializing Pipeline on {self.device}...")
        
        # [Step 3] Model Embedding (Bi-Encoder) - D√πng ƒë·ªÉ t√¨m ki·∫øm
        print("   ‚îú‚îÄ Loading Retriever (Bi-Encoder)...")
        self.retriever = SentenceTransformer('bkai-foundation-models/vietnamese-bi-encoder', device=self.device)
        
        # [Step 5] Model Verification (NLI) - Model b·∫°n train tr√™n Colab
        print("   ‚îú‚îÄ Loading Verifier (NLI Model)...")
        model_path = './my_model' 
        if not os.path.exists(model_path):
            raise Exception("‚ùå Thi·∫øu model! H√£y t·∫£i model train t·ª´ Colab v·ªÅ folder './my_model'")
        self.nli_model = CrossEncoder(model_path, device=self.device)
        
        print("‚úÖ Pipeline Ready!")

    def _get_db_connection(self):
        return psycopg2.connect(**DB_CONFIG)

    def run(self, article_text):
        """H√†m ch·∫°y to√†n b·ªô quy tr√¨nh ki·ªÉm tra"""
        
        # --- [Step 1 & 2] Segmentation & Extraction ---
        print("\n1Ô∏è‚É£ T√°ch c√¢u & Tr√≠ch xu·∫•t Claim...")
        raw_sentences = sent_tokenize(article_text)
        # Ch·ªâ l·∫•y c√¢u c√≥ ƒë·ªô d√†i > 5 t·ª´ (Coi l√† Claim)
        claims = [s for s in raw_sentences if len(s.split()) > 5]
        print(f"   -> T√¨m th·∫•y {len(claims)} claims quan tr·ªçng.")
        
        if not claims:
            return {"status": "ERROR", "reason": "B√†i vi·∫øt qu√° ng·∫Øn ho·∫∑c kh√¥ng c√≥ th√¥ng tin."}

        # --- [Step 3 & 4] Embedding & Retrieval ---
        print("2Ô∏è‚É£ T√¨m ki·∫øm b·∫±ng ch·ª©ng (Evidence Retrieval)...")
        claim_vectors = self.retriever.encode(claims)
        
        conn = self._get_db_connection()
        cur = conn.cursor()
        
        verified_claims = []
        
        for i, claim in enumerate(claims):
            # T√¨m 3 c√¢u trong kho d·ªØ li·ªáu REAL gi·ªëng nh·∫•t v·ªõi claim n√†y
            query = """
                SELECT content, (embedding <=> %s::vector) as distance
                FROM sentence_store
                ORDER BY distance ASC
                LIMIT 3;
            """
            cur.execute(query, (claim_vectors[i].tolist(),))
            results = cur.fetchall()
            
            # L·ªçc b·∫±ng ch·ª©ng: Ch·ªâ l·∫•y n·∫øu distance < 0.4 (t·ª©c l√† c√≥ li√™n quan v·ªÅ m·∫∑t ng·ªØ nghƒ©a)
            valid_evidence = [row[0] for row in results if row[1] < 0.4]
            
            # --- [Step 5] Verification (NLI) ---
            # N·∫øu kh√¥ng t√¨m th·∫•y b·∫±ng ch·ª©ng n√†o trong kho d·ªØ li·ªáu Real -> NEI (Not Enough Info)
            if not valid_evidence:
                verified_claims.append({
                    "claim": claim,
                    "evidence": None,
                    "status": "NEUTRAL", # Kh√¥ng th·ªÉ ki·ªÉm ch·ª©ng
                    "score": 0.5
                })
                continue
            
            # Gh√©p c·∫∑p Claim v·ªõi t·ª´ng Evidence ƒë·ªÉ AI ch·∫•m ƒëi·ªÉm
            pairs = [[ev, claim] for ev in valid_evidence]
            scores = self.nli_model.predict(pairs)
            
            # L·∫•y b·∫±ng ch·ª©ng c√≥ ƒëi·ªÉm cao nh·∫•t (t·ª©c l√† kh·ªõp nh·∫•t ho·∫∑c m√¢u thu·∫´n nh·∫•t)
            # V√¨ model train: 1=True, 0=Fake
            # N·∫øu ƒëi·ªÉm r·∫•t cao (>0.7) -> Evidence ·ª¶NG H·ªò Claim -> TRUE
            # N·∫øu ƒëi·ªÉm r·∫•t th·∫•p (<0.3) -> Evidence M√ÇU THU·∫™N Claim -> FAKE
            
            best_idx = np.argmax(scores) # V·ªã tr√≠ c·ªßa ƒëi·ªÉm cao nh·∫•t ch∆∞a ch·∫Øc t·ªët n·∫øu t·∫•t c·∫£ ƒë·ªÅu th·∫•p
            # Nh∆∞ng v·ªõi logic c·ªßa CrossEncoder 1 output:
            # Ta c·∫ßn xem x√©t gi√° tr·ªã score c·ª• th·ªÉ
            
            # L·∫•y score c·ª±c tr·ªã (quan t√¢m nh·∫•t l√† n√≥ R·∫•t ƒê√∫ng ho·∫∑c R·∫•t Sai)
            max_score = np.max(scores)
            min_score = np.min(scores)
            
            final_status = "NEUTRAL"
            final_score = 0.5
            best_ev = valid_evidence[0] # M·∫∑c ƒë·ªãnh
            
            # ∆Øu ti√™n b·∫Øt l·ªói Fake (n·∫øu c√≥ 1 b·∫±ng ch·ª©ng m√¢u thu·∫´n m·∫°nh -> FAKE)
            if min_score < 0.2: 
                final_status = "REFUTED" # Fake
                final_score = float(min_score)
                best_ev = valid_evidence[np.argmin(scores)]
            elif max_score > 0.7:
                final_status = "SUPPORTED" # True
                final_score = float(max_score)
                best_ev = valid_evidence[np.argmax(scores)]
            else:
                final_status = "NEUTRAL" # M∆° h·ªì
                final_score = float(max_score)
            
            verified_claims.append({
                "claim": claim,
                "evidence": best_ev,
                "status": final_status,
                "score": final_score
            })
            
        cur.close()
        conn.close()

        # --- [Step 6 & 7] Aggregation & Classification ---
        print("3Ô∏è‚É£ T·ªïng h·ª£p & K·∫øt lu·∫≠n...")
        
        # ƒê·∫øm s·ªë l∆∞·ª£ng
        n_refuted = sum(1 for c in verified_claims if c['status'] == 'REFUTED')
        n_supported = sum(1 for c in verified_claims if c['status'] == 'SUPPORTED')
        total = len(verified_claims)
        
        final_label = "NEUTRAL"
        explanation = "Kh√¥ng ƒë·ªß d·ªØ li·ªáu ƒë·ªÉ x√°c th·ª±c."
        confidence = 0.0
        
        if n_refuted > 0:
            # Ch·ªâ c·∫ßn 1 c√¢u n√≥i l√°o -> C·∫£ b√†i FAKE (nguy√™n t·∫Øc nghi√™m ng·∫∑t)
            final_label = "FAKE"
            explanation = f"Ph√°t hi·ªán {n_refuted} th√¥ng tin sai l·ªách so v·ªõi c∆° s·ªü d·ªØ li·ªáu."
            # L·∫•y ƒë·ªô tin c·∫≠y t·ª´ c√°c c√¢u b·ªã refute
            confidence = 1 - (sum(c['score'] for c in verified_claims if c['status'] == 'REFUTED') / n_refuted)
            
        elif n_supported > (total * 0.5): # H∆°n 50% c√¢u ƒë∆∞·ª£c x√°c th·ª±c ƒë√∫ng
            final_label = "REAL"
            explanation = f"X√°c th·ª±c ƒë∆∞·ª£c {n_supported}/{total} th√¥ng tin kh·ªõp v·ªõi d·ªØ li·ªáu g·ªëc."
            confidence = sum(c['score'] for c in verified_claims if c['status'] == 'SUPPORTED') / n_supported
            
        return {
            "label": final_label,
            "confidence": confidence,
            "explanation": explanation,
            "details": verified_claims
        }

# --- TEST ---
if __name__ == "__main__":
    pipeline = FactCheckerPipeline()
    
    # Test 1: B√†i Fake (Sai s·ªë li·ªáu)
    fake_text = "Th·ªï Nhƒ© K·ª≥ ƒëi·ªÅu 500 m√°y bay s∆° t√°n c√¥ng d√¢n. ƒê√¢y l√† chi·∫øn d·ªãch l·ªõn nh·∫•t l·ªãch s·ª≠."
    
    result = pipeline.run(fake_text)
    
    print("\n" + "="*30)
    print(f"üõë K·∫æT QU·∫¢: {result['label']} ({result['confidence']:.2%})")
    print(f"üí° L√Ω do: {result['explanation']}")
    print("-" * 30)
    for detail in result['details']:
        if detail['status'] != 'NEUTRAL':
            print(f"[{detail['status']}] Claim: {detail['claim']}")
            print(f"   -> Evid: {detail['evidence']}")
            print(f"   -> Score: {detail['score']:.4f}")