import psycopg2
import torch
import numpy as np
import os
import re
from underthesea import sent_tokenize
from sentence_transformers import SentenceTransformer, CrossEncoder
from dotenv import load_dotenv

load_dotenv()

# --- C·∫§U H√åNH ---
DB_CONFIG = {
    "dbname": os.getenv("POSTGRES_DB", "vnexpress_scraper"),
    "user": os.getenv("POSTGRES_USER", "admin"),
    "password": os.getenv("POSTGRES_PASSWORD", "admin"),
    "host": "localhost",
    "port": "5432"
}

# ƒê∆∞·ªùng d·∫´n Model V6 (Hard Negative)
MODEL_PATH = "model/phobert_v6_hard_negative" 

class AdvancedFactChecker:
    def __init__(self):
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        print(f"üöÄ [Verifier] KH·ªûI ƒê·ªòNG DECISION ENGINE TR√äN {self.device.upper()}...")

        # 1. RETRIEVER (Bi-Encoder)
        print("   ‚îú‚îÄ [1/2] Loading Retriever...")
        self.retriever = SentenceTransformer('bkai-foundation-models/vietnamese-bi-encoder', device=self.device)

        # 2. VERIFIER (Cross-Encoder V6)
        print(f"   ‚îú‚îÄ [2/2] Loading Verifier V6 t·ª´ {MODEL_PATH}...")
        try:
            # Model V6 train b·∫±ng CrossEncoder, n√™n load b·∫±ng class CrossEncoder s·∫Ω chu·∫©n h∆°n AutoModel
            self.verifier_model = CrossEncoder(MODEL_PATH, device=self.device)
            print("      ‚úÖ Model V6 ƒë√£ s·∫µn s√†ng!")
        except Exception as e:
            print(f"      ‚ùå L·ªñI LOAD MODEL: {e}")
            raise RuntimeError("Kh√¥ng t√¨m th·∫•y model. H√£y ƒë·∫£m b·∫£o folder model ƒë√∫ng v·ªã tr√≠.")

    def clean_text(self, text):
        """V·ªá sinh vƒÉn b·∫£n ƒë·∫ßu v√†o"""
        if not text: return ""
        text = str(text).replace('\n', '. ').replace('\r', '. ').replace('\t', ' ')
        text = re.sub(r'\.\.+', '.', text)
        text = re.sub(r'\s+', ' ', text).strip()
        return text

    def extract_claims(self, text):
        """T√°ch vƒÉn b·∫£n th√†nh c√°c c√¢u ƒë∆°n"""
        cleaned_text = self.clean_text(text)
        sentences = sent_tokenize(cleaned_text)
        # L·ªçc c√¢u qu√° ng·∫Øn
        return [s.strip() for s in sentences if len(s.split()) > 5]

    def verify(self, article_text):
        """
        Lu·ªìng ki·ªÉm ch·ª©ng ch√≠nh:
        1. T√°ch input th√†nh c√°c claims.
        2. V·ªõi m·ªói claim, t√¨m ki·∫øm trong DB (Ch·ªâ t√¨m REAL claims).
        3. D√πng Model V6 so s√°nh -> Ra quy·∫øt ƒë·ªãnh.
        """
        claims = self.extract_claims(article_text)
        if not claims: 
            return {"status": "NEUTRAL", "confidence": 0.0, "explanation": "N·ªôi dung qu√° ng·∫Øn ho·∫∑c kh√¥ng ƒë·ªß th√¥ng tin.", "details": []}

        # M√£ h√≥a Claims input ƒë·ªÉ t√¨m ki·∫øm
        claim_vectors = self.retriever.encode(claims)
        
        conn = psycopg2.connect(**DB_CONFIG)
        results_list = []
        
        with conn.cursor() as cur:
            for i, claim in enumerate(claims):
                # --- QUAN TR·ªåNG: S·ª¨A SQL QUERY ---
                # Ch·ªâ l·∫•y nh·ªØng claim c√≥ system_label = 'REAL'
                cur.execute("""
                    SELECT content, system_label, (embedding <=> %s::vector) as distance
                    FROM claims
                    WHERE system_label = 'REAL' 
                    ORDER BY distance ASC
                    LIMIT 1; 
                """, (claim_vectors[i].tolist(),))
                
                row = cur.fetchone()
                
                # M·∫∑c ƒë·ªãnh l√† NEUTRAL n·∫øu kh√¥ng t√¨m th·∫•y b·∫±ng ch·ª©ng
                status = "NEUTRAL"
                evidence_text = "Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu ƒë·ªëi chi·∫øu."
                confidence = 0.5
                scores_debug = [0, 0, 0]

                # N·∫øu t√¨m th·∫•y ·ª©ng vi√™n trong DB v√† kho·∫£ng c√°ch vector ƒë·ªß g·∫ßn (< 0.5)
                if row and row[2] < 0.5:
                    evidence_text = row[0]
                    
                    # D√πng Model V6 ph√°n x√©t (0: Fake, 1: Real, 2: NEI)
                    scores = self.verifier_model.predict([claim, evidence_text])
                    scores_softmax = np.exp(scores) / np.sum(np.exp(scores)) # Softmax th·ªß c√¥ng
                    pred_label = np.argmax(scores_softmax)
                    confidence = float(scores_softmax[pred_label])
                    scores_debug = scores_softmax.tolist()

                    if pred_label == 0:   # REFUTES
                        status = "REFUTED"
                    elif pred_label == 1: # SUPPORTS
                        status = "SUPPORTED"
                    else:
                        status = "NEI"

                results_list.append({
                    "claim": claim, 
                    "status": status, 
                    "evidence": evidence_text, 
                    "score": confidence,
                    "probs": scores_debug
                })
        
        conn.close()
        return self.make_final_decision(results_list)

    def make_final_decision(self, details):
        """Logic t·ªïng h·ª£p k·∫øt qu·∫£ (Decision Engine)"""
        refuted_items = [d for d in details if d['status'] == 'REFUTED']
        supported_items = [d for d in details if d['status'] == 'SUPPORTED']
        
        # RULE 1: C√≥ b·∫±ng ch·ª©ng b√°c b·ªè m·∫°nh (> 85%) -> FAKE
        strong_fakes = [d for d in refuted_items if d['score'] > 0.85]
        if strong_fakes:
            top = strong_fakes[0]
            return {
                "status": "FAKE",
                "confidence": top['score'],
                "explanation": f"Th√¥ng tin sai l·ªách: '{top['claim']}' m√¢u thu·∫´n v·ªõi d·ªØ li·ªáu g·ªëc.",
                "details": details
            }

        # RULE 2: H·∫ßu h·∫øt l√† ·ªßng h·ªô -> REAL
        if len(supported_items) >= len(details) * 0.5 and not refuted_items:
            avg_score = sum(d['score'] for d in supported_items) / len(supported_items)
            return {
                "status": "REAL",
                "confidence": avg_score,
                "explanation": "N·ªôi dung kh·ªõp v·ªõi d·ªØ li·ªáu ƒë√£ x√°c th·ª±c.",
                "details": details
            }

        # RULE 3: C√≤n l·∫°i -> NEUTRAL (Ch∆∞a ƒë·ªß th√¥ng tin)
        return {
            "status": "NEUTRAL",
            "confidence": 0.5,
            "explanation": "H·ªá th·ªëng ch∆∞a c√≥ ƒë·ªß d·ªØ li·ªáu x√°c th·ª±c (REAL) cho th√¥ng tin n√†y.",
            "details": details
        }